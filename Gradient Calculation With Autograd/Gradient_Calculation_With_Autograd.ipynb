{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YilSTdGYyhbz"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Mte_Z9LkyiwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0571f5e1-2352-4d36-a8c0-eeb887c883bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7484, -2.1737,  0.1608])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We want to calculate the gradient of some function with respect to X then we must specify the argument requires grad ***"
      ],
      "metadata": {
        "id": "eYGtS2IxzQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p4AJcLvzJaa",
        "outputId": "4372e104-ec7c-4c1f-8cb4-28f84cbe2169"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3894, -0.6472, -1.1848], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now whenever we do operations with this tensor pi torch will create so called computational graph for us \n",
        "\n",
        "y = x+2 \n",
        "print(y)\n",
        "z = y*y*2\n",
        "z = z.mean() # Our gradient fucntion is the mean backward \n",
        "print(z) \n",
        "\n",
        "z.backward() # Going to calculate dz/dx\n",
        "print(x.grad) # Gradients are stored \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaWvVPoNzsVF",
        "outputId": "d3dd3172-72cb-4156-990b-bbfd45ebfff6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.6106, 1.3528, 0.8152], grad_fn=<AddBackward0>)\n",
            "tensor(3.3926, grad_fn=<MeanBackward0>)\n",
            "tensor([2.1475, 1.8038, 1.0870])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preventing Gradient History***"
      ],
      "metadata": {
        "id": "0J9Zq1iZQr4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For preventing from tracking the gradients we have 3 options for this\n",
        "# 1st -> x.requires_grad_(Flase)\n",
        "# 2nd -> x.detach()\n",
        "# 3rd -> with torch.no_grad()"
      ],
      "metadata": {
        "id": "VaN1Ib7F0HHP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st\n",
        "\n",
        "x.requires_grad_(False)\n",
        "print(x)\n",
        "\n",
        "# 2nd\n",
        "\n",
        "y = x.detach()\n",
        "print(y)\n",
        "\n",
        "# 3rd\n",
        "\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)\n",
        "\n",
        "\n",
        "# Those are the three ways how we can stop pytorch from creating this gradient fucntions \n",
        "# and tracking the history in our computational graph "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44k0OvUyRDKc",
        "outputId": "6bcfcdcf-b942-4d89-f237-e9c59a19f89a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3894, -0.6472, -1.1848])\n",
            "tensor([-0.3894, -0.6472, -1.1848])\n",
            "tensor([1.6106, 1.3528, 0.8152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Gradient for this tensor will be accumulated into .grad attributes their values will be summed up  ***"
      ],
      "metadata": {
        "id": "CBUBtvroTKJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy training example \n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMhwiAGZRUhv",
        "outputId": "54b2a805-e71e-494c-9f17-2bc9d213c117"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Incorrect gradients so we must empty the gradients \n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpBKfA1pTzQk",
        "outputId": "58bbf36b-0840-4758-af04-e19d22d6d4c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Pytorch's built-in optimizier*** "
      ],
      "metadata": {
        "id": "vGgyc8GrUSYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple model with learnable parameters\n",
        "model = nn.Linear(4, 1)\n",
        "\n",
        "# Pass the model parameters to the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "zuebeZWVUPom"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKQS0UlXU1F6"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}