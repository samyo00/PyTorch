{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3FFoE-dyyNJu"
      },
      "outputs": [],
      "source": [
        "# We had a dataset then we have our tranining loop over the number of epochs then we optimized our model based on the while data set\n",
        "# This is very time consuming if we did gradient calculations on the whole traning data\n",
        "\n",
        "# So batter way for large datasets is to divide the samples into so called smaller batches then we loop over the epochs\n",
        "# Another loop over batches then we get the x & y batch samples \n",
        "# Then we do the optimization based on only those batches  \n",
        "\n",
        "# Now if we use built-in data set and data loader classes from pyTorch then pyTorch can do batch calcualation and iterations for us"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 epoch = 1 farward and backward pass of ALL TRAINING examples\n",
        "\n",
        "batch_size = number of TRAINING samples in one forward & backward pass\n",
        "\n",
        "number of iterations = number of passes, each pass uing [batch_size] number of samples\n",
        "\n",
        "e.g 100 samples, batch size = 20 --> 100/20 = 5 interations for 1 epoch"
      ],
      "metadata": {
        "id": "M7q2uWjS7wc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "IKfLohi6yRX6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Dataset "
      ],
      "metadata": {
        "id": "dRQdNTJs-PtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "uTWR25L_9z9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4479ecd4-36b9-40f0-aba4-154d2c7a26ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how we use dataloader \n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "_1jtMiVvB8lY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014f490b-454d-40f7-c746-27daeb94eb7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3580e+01, 2.5800e+00, 2.6900e+00, 2.4500e+01, 1.0500e+02, 1.5500e+00,\n",
            "         8.4000e-01, 3.9000e-01, 1.5400e+00, 8.6600e+00, 7.4000e-01, 1.8000e+00,\n",
            "         7.5000e+02],\n",
            "        [1.3480e+01, 1.6700e+00, 2.6400e+00, 2.2500e+01, 8.9000e+01, 2.6000e+00,\n",
            "         1.1000e+00, 5.2000e-01, 2.2900e+00, 1.1750e+01, 5.7000e-01, 1.7800e+00,\n",
            "         6.2000e+02],\n",
            "        [1.2770e+01, 3.4300e+00, 1.9800e+00, 1.6000e+01, 8.0000e+01, 1.6300e+00,\n",
            "         1.2500e+00, 4.3000e-01, 8.3000e-01, 3.4000e+00, 7.0000e-01, 2.1200e+00,\n",
            "         3.7200e+02],\n",
            "        [1.4190e+01, 1.5900e+00, 2.4800e+00, 1.6500e+01, 1.0800e+02, 3.3000e+00,\n",
            "         3.9300e+00, 3.2000e-01, 1.8600e+00, 8.7000e+00, 1.2300e+00, 2.8200e+00,\n",
            "         1.6800e+03]]) tensor([[3.],\n",
            "        [3.],\n",
            "        [2.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dummy Training loop***"
      ],
      "metadata": {
        "id": "gH9FDeccxaa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples,n_iterations)"
      ],
      "metadata": {
        "id": "UaCv8FgCB-zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9ac2f6-5fe1-4e85-a714-45cb4afc9639"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do our loops\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-rgVb3Lxxuu",
        "outputId": "00159e1c-dae3-48b1-8ce6-45b2e2dba89c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peHEYKSFzv0k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}